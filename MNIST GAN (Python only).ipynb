{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "equipped-berkeley",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from tqdm import trange\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "naval-sydney",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data import \n",
    "\n",
    "def fetch(url):\n",
    "    import requests, gzip, os, hashlib, numpy\n",
    "    path = os.path.join(os.getcwd(), hashlib.md5(url.encode('utf-8')).hexdigest())\n",
    "    if os.path.isfile(path):\n",
    "        with open(path, 'rb') as f:\n",
    "            dat = f.read()\n",
    "    else:\n",
    "        with open(path, 'wb') as f:\n",
    "            dat = requests.get(url).content\n",
    "            f.write(dat)\n",
    "    return numpy.frombuffer(gzip.decompress(dat), dtype=numpy.uint8).copy()\n",
    "\n",
    "X_train = fetch('http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz')[0x10:].reshape((-1, 28, 28))\n",
    "Y_train = fetch('http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz')[8:]\n",
    "X_test = fetch('http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz')[0x10:].reshape((-1, 28, 28))\n",
    "Y_test = fetch('http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz')[8:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biological-administrator",
   "metadata": {},
   "source": [
    "# GAN Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "monthly-telephone",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer function definition (from MNIST Classifier)\n",
    "\n",
    "import abc\n",
    "\n",
    "class LayerFunction:\n",
    "    __metaclass__ = abc.ABCMeta\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.evaluate(*args, **kwargs)\n",
    "        \n",
    "    @abc.abstractmethod\n",
    "    def evaluate(self, *args, **kwargs):\n",
    "        pass\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def backprop(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "# Activation function definition\n",
    "\n",
    "class ActivationFunction(LayerFunction):\n",
    "    \n",
    "    def __init__(self, axis=1):\n",
    "        self.axis = axis\n",
    "        self.grad = 0\n",
    "    \n",
    "\n",
    "class ReLU(ActivationFunction):\n",
    "    \n",
    "    def evaluate(self, x):\n",
    "        return np.maximum(x, 0)\n",
    "    \n",
    "    def backprop(self, dD, x):\n",
    "        return (x > 0).astype(int)*dD\n",
    "\n",
    "\n",
    "class LogSoftmax(ActivationFunction):\n",
    "        \n",
    "    def evaluate(self, x):\n",
    "        x = x - x.max(1).reshape(-1, 1)\n",
    "        x = x - np.log(np.exp(x).sum(1)).reshape(-1, 1)\n",
    "        return x\n",
    "            \n",
    "    def backprop(self, dD, x):\n",
    "        exp_lsm = np.exp(self.evaluate(x))\n",
    "        dLSM = dD - exp_lsm*dD.sum(axis=self.axis).reshape((-1, 1))\n",
    "        return dLSM\n",
    "    \n",
    "\n",
    "class Tanh(ActivationFunction):\n",
    "    \n",
    "    def evaluate(self, x):\n",
    "        return (np.exp(x) - np.exp(-x)) / (np.exp(x) + np.exp(-x))\n",
    "    \n",
    "    def backprop(self, dD, x):\n",
    "        cosh = (np.exp(x) + np.exp(-x)) * 0.5\n",
    "        return dD / (cosh**2)\n",
    "        \n",
    "\n",
    "# Loss function definition\n",
    "\n",
    "class LossFunction(LayerFunction):\n",
    "\n",
    "    def __init__(self, axis=0):\n",
    "        self.axis = axis \n",
    "    \n",
    "\n",
    "class NLLLoss(LossFunction):\n",
    "    \n",
    "    def evaluate(self, x, labels):\n",
    "        if self.axis == 0:\n",
    "            return -np.mean(x[np.arange(x.shape[0]), labels])\n",
    "    \n",
    "    def backprop(self, x, y):\n",
    "        dx = np.zeros(x.shape, dtype=x.dtype)\n",
    "        if self.axis == 0:\n",
    "            dx[np.arange(x.shape[0]), y.T] = -1/len(y)\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "toxic-refrigerator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator class\n",
    "\n",
    "class Generator:\n",
    "    \n",
    "    def __init__(self, l0=128, l1=256, l2=256**2, l3=256**4, l4=28*28, dtype=np.float32):\n",
    "        self.w1 = np.random.uniform(-1., 1., shape=(l1, l2))/np.sqrt(l0*l1).astype(dtype)\n",
    "        self.w2 = np.random.uniform(-1., 1., shape=(l2, l3))/np.sqrt(l1*l2).astype(dtype)\n",
    "        self.w3 = np.random.uniform(-1., 1., shape=(l3, l4))/np.sqrt(l2*l3).astype(dtype)\n",
    "        self.w4 = np.random.uniform(-1., 1., shape=(l4, l5))/np.sqrt(l3*l4).astype(dtype)\n",
    "        \n",
    "        self.act1 = ReLU()\n",
    "        self.act2 = ReLU()\n",
    "        self.act3 = ReLU()\n",
    "        self.act4 = Tanh()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.dot(self.w1)\n",
    "        x = self.act1(x)\n",
    "        x = x.dot(self.w2)\n",
    "        x = self.act2(x)\n",
    "        x = x.dot(self.w3)\n",
    "        x = self.act3(x)\n",
    "        x = x.dot(self.w4)\n",
    "        x = self.act4(x)\n",
    "        return x\n",
    "    \n",
    "    def forward_backward(self, a0, D, loss_function):\n",
    "                    \n",
    "        # Forward pass\n",
    "        z1 = a0.dot(self.w1)\n",
    "        a1 = self.act1(z1)\n",
    "        z2 = a1.dot(self.w2)\n",
    "        a2 = self.act2(z2)\n",
    "        z3 = a2.dot(self.w3)\n",
    "        a3 = self.act3(z3)\n",
    "        z4 = a3.dot(self.w4)\n",
    "        a4 = self.act4(z4)\n",
    "        \n",
    "        # Loss and accuracy\n",
    "        loss = loss_function(a4, y)\n",
    "        accuracy = (np.argmax(a2, axis=1) == y).mean()\n",
    "\n",
    "        # Backward pass\n",
    "        da4 = loss_function.backprop(a4, y)\n",
    "        dz4 = self.act4.backprop(da4, z4)\n",
    "        dw4 = a3.T.dot(dz4) \n",
    "        da3 = dz4.dot(self.w4.T)\n",
    "        dz3 = self.act3.backprop(da3, z3)\n",
    "        dw3 = a2.T.dot(dz3) \n",
    "        da2 = dz3.dot(self.w3.T)\n",
    "        dz2 = self.act2.backprop(da2, z2)\n",
    "        dw2 = a1.T.dot(dz2) \n",
    "        da1 = dz2.dot(self.w2.T)\n",
    "        dz1 = self.act1.backprop(da1, z1)\n",
    "        dw1 = a0.T.dot(dz1)\n",
    "        \n",
    "        # Return loss and gradients\n",
    "        grad = {'w1': dw1, 'w2': dw2, 'w3': dw3, 'w4': dw4}\n",
    "        return loss, accuracy, grad\n",
    "\n",
    "    \n",
    "# Discriminator class\n",
    "\n",
    "class Discriminator:\n",
    "    \n",
    "    def __init__(self, l1=28*28, l2=1000, l3=256, l4=1, dtype=np.float32):\n",
    "        self.w1 = np.random.uniform(-1., 1., shape=(l1, l2))/np.sqrt(l1*l2).astype(dtype)\n",
    "        self.w2 = np.random.uniform(-1., 1., shape=(l2, l3))/np.sqrt(l2*l3).astype(dtype)\n",
    "        self.w3 = np.random.uniform(-1., 1., shape=(l3, l4))/np.sqrt(l3*l4).astype(dtype)\n",
    "        \n",
    "        self.act1 = ReLU()\n",
    "        self.act2 = ReLU()\n",
    "        self.act3 = Tanh()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.dot(self.w1)\n",
    "        x = self.act1(x)\n",
    "        x = x.dot(self.w2)\n",
    "        x = self.act2(x)\n",
    "        x = x.dot(self.w3)\n",
    "        x = self.act3(x)\n",
    "        return x\n",
    "    \n",
    "    def forward_backward(self, a0, loss_function):\n",
    "        \n",
    "\n",
    "# GAN class\n",
    "\n",
    "class GAN:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.G = Generator()\n",
    "        self.D = Discriminator()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
